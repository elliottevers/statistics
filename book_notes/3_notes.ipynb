{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.quora.com/Explain-VC-dimension-and-shattering-in-lucid-Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a (binary) classifier, we want to find a surface that separates data.  The VC dimension gives us a way to rank functions that could be used to do this, and conduct the search in a structured manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirical CDF\n",
    "```\n",
    "Percentage empirical_cdf(RandomVariable... X | x \\in X has CDF F, Real t){\n",
    "    # we essentially have length(X) samples, and we're determining the percentage of samples that are less than t\n",
    "    Natural n = length(X)\n",
    "    return sum([indicator(x <= t) for x in X])/n\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we collect more samples, we want the empirical CDF to converge to $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Error, Risk:\n",
    "\n",
    "```\n",
    "typedef Function<Real -> Bit> Classifier\n",
    "```\n",
    "\n",
    "```\n",
    "Probability risk(\n",
    "    RandomVariable X,\n",
    "    RandomVariable Y,\n",
    "    Classifier h\n",
    "){\n",
    "    return P(Y != h(X))\n",
    "}\n",
    "```\n",
    "\n",
    "Training Error:\n",
    "```\n",
    "Percentage training_error(\n",
    "    List<Tuple<X, Y>> observations,\n",
    "    Classifier h\n",
    "){\n",
    "    const DATA = 0\n",
    "    const CLASS = 1\n",
    "    return sum([indicator(h(obs[DATA]) == obs[LABEL]) for obs in observations])/length(X)\n",
    "}\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can bound the difference between training error and risk using Hoeffding's inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Bit linear_classifier(\n",
    "    List<Real> β,\n",
    "    List<Real> x\n",
    "){\n",
    "    return 1 if dot(β, x) >= 0 else 0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How close is (true error of classifier that minimizes training error) to \n",
    "(true error of classifier that minimizes true error)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniform Bound:\n",
    "```\n",
    "Proposition<\n",
    "    Probability<\n",
    "        Difference<\n",
    "            ... # difference between number of elements in P_n and P\n",
    "        >\n",
    "    >,\n",
    "    Expression<\n",
    "        Set<\n",
    "            Set<\n",
    "                ... # training sets\n",
    "            >\n",
    "        >,\n",
    "        \n",
    "    >\n",
    "> uniform_bound(\n",
    "){\n",
    "    \n",
    "    return \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
